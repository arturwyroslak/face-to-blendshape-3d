import * as THREE from 'three';
import { OrbitControls } from 'three/examples/jsm/controls/OrbitControls.js';
import { GLTFExporter } from 'three/examples/jsm/exporters/GLTFExporter.js';
import { GLTFLoader } from 'three/examples/jsm/loaders/GLTFLoader.js';
import { FaceLandmarker, FilesetResolver } from '@mediapipe/tasks-vision';
import { ARKitBlendshapeMapper } from './arkit-mapper.js';
import { FaceMeshGenerator } from './face-mesh-generator.js';
import { TextureMapper } from './texture-mapper.js';
import headModelUrl from '../head.glb?url';

class FaceToBlendshape3D {
    constructor() {
        this.faceLandmarker = null;
        this.scene = null;
        this.camera = null;
        this.renderer = null;
        this.controls = null;
        this.faceMesh = null;
        this.headModel = null;
        this.blendshapes = {};
        this.currentImage = null;
        this.textureCanvas = null;
        this.init();
    }

    async init() {
        await this.initMediaPipe();
        this.initThreeJS();
        this.initEventListeners();
        this.animate();
    }

    async initMediaPipe() {
        const vision = await FilesetResolver.forVisionTasks(
            'https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@latest/wasm'
        );

        this.faceLandmarker = await FaceLandmarker.createFromOptions(vision, {
            baseOptions: {
                modelAssetPath:
                    'https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/latest/face_landmarker.task',
                delegate: 'GPU'
            },
            outputFaceBlendshapes: true,
            outputFacialTransformationMatrixes: true,
            runningMode: 'IMAGE',
            numFaces: 1
        });
    }

    initThreeJS() {
        const canvas = document.getElementById('canvas3d');
        const container = canvas.parentElement;

        this.scene = new THREE.Scene();
        this.scene.background = new THREE.Color(0xf8f9ff);

        this.camera = new THREE.PerspectiveCamera(
            45,
            container.clientWidth / container.clientHeight,
            0.1,
            1000
        );
        this.camera.position.z = 2;

        this.renderer = new THREE.WebGLRenderer({
            canvas,
            antialias: true,
            preserveDrawingBuffer: true
        });

        this.renderer.setSize(container.clientWidth, container.clientHeight);
        this.renderer.setPixelRatio(window.devicePixelRatio);

        this.controls = new OrbitControls(this.camera, canvas);
        this.controls.enableDamping = true;

        // OÅ›wietlenie
        const ambient = new THREE.AmbientLight(0xffffff, 0.9);
        this.scene.add(ambient);
        const front = new THREE.DirectionalLight(0xffffff, 1.0);
        front.position.set(0, 0, 5);
        this.scene.add(front);
        const top = new THREE.DirectionalLight(0xffffff, 0.8);
        top.position.set(0, 5, 0);
        this.scene.add(top);

        // Åadowanie modelu gÅ‚owy
        const loader = new GLTFLoader();
        loader.load(headModelUrl, (gltf) => {
            this.headModel = gltf.scene;

            // Ustawienie materiaÅ‚u dla gÅ‚owy (baza)
            this.headModel.traverse((child) => {
                if (child.isMesh) {
                    child.material = new THREE.MeshStandardMaterial({
                        color: new THREE.Color(0.85, 0.65, 0.55), // Bardziej naturalny kolor skÃ³ry
                        roughness: 0.5,
                        metalness: 0.0
                    });
                }
            });

            // WyÅ›rodkowanie modelu gÅ‚owy wzglÄ™dem jego wÅ‚asnego pivotu
            const box = new THREE.Box3().setFromObject(this.headModel);
            const center = box.getCenter(new THREE.Vector3());
            this.headModel.position.sub(center);

            this.scene.add(this.headModel);
            this.headModel.visible = false;
        });

        window.addEventListener('resize', () => this.onResize());
    }

    initEventListeners() {
        const uploadArea = document.getElementById('uploadArea');
        const fileInput = document.getElementById('fileInput');
        const processBtn = document.getElementById('processBtn');
        const exportBtn = document.getElementById('exportBtn');

        uploadArea.addEventListener('click', () => fileInput.click());

        fileInput.addEventListener('change', (e) => {
            const file = e.target.files[0];
            if (file) this.loadImage(file);
        });

        processBtn.addEventListener('click', () => this.processImage());
        exportBtn.addEventListener('click', () => this.exportGLB());
    }

    loadImage(file) {
        const reader = new FileReader();
        reader.onload = (e) => {
            const img = new Image();
            img.onload = () => {
                this.currentImage = img;
                document.getElementById('processBtn').disabled = false;
            };
            img.src = e.target.result;
        };
        reader.readAsDataURL(file);
    }

    async processImage() {
        if (!this.currentImage) return;

        const results = this.faceLandmarker.detect(this.currentImage);
        if (!results.faceLandmarks?.length) return;

        const landmarks = results.faceLandmarks[0];
        const blendshapes = results.faceBlendshapes?.[0]?.categories || [];
        const transformMatrix = results.facialTransformationMatrixes?.[0];

        // 1. Generowanie blendshapes i tekstury
        const mapper = new ARKitBlendshapeMapper();
        this.blendshapes = mapper.mapMediaPipeToARKit(blendshapes, landmarks);

        const textureMapper = new TextureMapper();
        this.textureCanvas = textureMapper.createFaceTexture(
            this.currentImage,
            landmarks
        );

        // 2. Generowanie siatki twarzy (maski)
        const meshGenerator = new FaceMeshGenerator();
        this.faceMesh = meshGenerator.generateWithMorphTargets(
            landmarks,
            this.blendshapes,
            transformMatrix,
            this.textureCanvas
        );

        // UsuniÄ™cie starej siatki jeÅ›li istnieje
        const oldMesh = this.scene.getObjectByName('faceMesh');
        if (oldMesh) this.scene.remove(oldMesh);

        this.faceMesh.name = 'faceMesh';
        this.scene.add(this.faceMesh);

        // =========================================================
        // ðŸ”¥ TU SÄ„ GÅÃ“WNE ZMIANY DO SKALOWANIA ðŸ”¥
        // =========================================================

        // Krok A: ZwÄ™Å¼enie samej maski twarzy (zgodnie z Å¼yczeniem)
        this.faceMesh.scale.x = 0.92; // Lekkie zwÄ™Å¼enie
        this.faceMesh.updateMatrixWorld(true);

        if (this.headModel) {
            this.headModel.visible = true;

            // 1. Obliczamy wymiary pudeÅ‚ka (Bounding Box) twarzy
            this.faceMesh.geometry.computeBoundingBox();
            const faceBox = this.faceMesh.geometry.boundingBox;
            const faceSize = new THREE.Vector3();
            faceBox.getSize(faceSize);
            const faceCenter = new THREE.Vector3();
            faceBox.getCenter(faceCenter); // Pobieramy Å›rodek twarzy

            // Zastosowanie skali obiektu do wymiarÃ³w z geometrii
            const faceWidthWorld = faceSize.x * this.faceMesh.scale.x;
            const faceHeightWorld = faceSize.y * this.faceMesh.scale.y;

            // 2. Obliczamy wymiary pudeÅ‚ka gÅ‚owy (nieprzeskalowanej)
            // Resetujemy skalÄ™ gÅ‚owy na chwilÄ™, Å¼eby pobraÄ‡ czyste wymiary
            this.headModel.scale.set(1, 1, 1);
            this.headModel.updateMatrixWorld(true);
            
            const headBox = new THREE.Box3().setFromObject(this.headModel);
            const headSize = new THREE.Vector3();
            headBox.getSize(headSize);

            // 3. Obliczamy potrzebnÄ… skalÄ™
            // Chcemy, Å¼eby gÅ‚owa byÅ‚a znacznie szersza niÅ¼ sama maska twarzy (np. 2.2 razy szersza),
            // poniewaÅ¼ maska to tylko przÃ³d, a gÅ‚owa musi obejmowaÄ‡ caÅ‚oÅ›Ä‡.
            // Poprzednio ten mnoÅ¼nik byÅ‚ za maÅ‚y (1.15), dlatego gÅ‚owa byÅ‚a malutka.
            const widthRatio = (faceWidthWorld * 2.3) / headSize.x;
            const heightRatio = (faceHeightWorld * 1.5) / headSize.y; // Mniejszy mnoÅ¼nik na wysokoÅ›Ä‡

            // Wybieramy wiÄ™kszÄ… skalÄ™, Å¼eby gÅ‚owa nie byÅ‚a za maÅ‚a w Å¼adnym wymiarze
            const targetScale = Math.max(widthRatio, heightRatio);

            console.log("Skala gÅ‚owy:", targetScale); // Debug

            this.headModel.scale.set(targetScale, targetScale, targetScale);
            this.headModel.updateMatrixWorld(true);

            // 4. Pozycjonowanie
            // Ustawiamy gÅ‚owÄ™ w centrum twarzy
            const scaledHeadBox = new THREE.Box3().setFromObject(this.headModel);
            const scaledHeadCenter = new THREE.Vector3();
            scaledHeadBox.getCenter(scaledHeadCenter);

            const offset = new THREE.Vector3().subVectors(faceCenter, scaledHeadCenter);
            this.headModel.position.add(offset);

            // 5. Korekta gÅ‚Ä™bokoÅ›ci (Z) - kluczowe dla wtapiania
            // Przesuwamy gÅ‚owÄ™ w tyÅ‚ wzglÄ™dem twarzy, ale nie za daleko.
            // Im mniejsza wartoÅ›Ä‡ odejmowana, tym gÅ‚owa jest "bliÅ¼ej" przodu twarzy.
            const scaledHeadDepth = scaledHeadBox.max.z - scaledHeadBox.min.z;
            
            // Przesuwamy gÅ‚owÄ™ tak, Å¼eby jej Å›rodek byÅ‚ nieco za twarzÄ….
            // WartoÅ›Ä‡ 0.15 jest eksperymentalna - reguluje jak bardzo uszy/tyÅ‚ gÅ‚owy wystajÄ….
            this.headModel.position.z += scaledHeadDepth * 0.15; 

            // Upewniamy siÄ™, Å¼e twarz jest zawsze przed gÅ‚owÄ… w kolejnoÅ›ci renderowania
            this.faceMesh.renderOrder = 2;
            this.headModel.renderOrder = 1;

            // Opcjonalnie: PrÃ³bujemy dopasowaÄ‡ kolor gÅ‚owy do Å›redniego koloru twarzy
            // (JeÅ›li w faceMesh.userData zapisaÅ‚eÅ› kolor skÃ³ry w generatorze)
            if (this.faceMesh.userData.skinColor) {
                 const sc = this.faceMesh.userData.skinColor;
                 this.headModel.traverse((child) => {
                    if(child.isMesh) {
                        child.material.color.setRGB(sc.r, sc.g, sc.b);
                    }
                 });
            }
        }

        document.getElementById('exportBtn').disabled = false;
    }

    async exportGLB() {
        if (!this.faceMesh) return;

        const exporter = new GLTFExporter();
        const group = new THREE.Group();

        group.add(this.faceMesh.clone());
        if (this.headModel?.visible)
            group.add(this.headModel.clone());

        exporter.parse(
            group,
            (result) => {
                const blob = new Blob([result], {
                    type: 'application/octet-stream'
                });
                const link = document.createElement('a');
                link.href = URL.createObjectURL(blob);
                link.download = 'face-model.glb';
                link.click();
            },
            { binary: true }
        );
    }

    onResize() {
        const container = this.renderer.domElement.parentElement;
        this.camera.aspect =
            container.clientWidth / container.clientHeight;
        this.camera.updateProjectionMatrix();
        this.renderer.setSize(
            container.clientWidth,
            container.clientHeight
        );
    }

    animate() {
        requestAnimationFrame(() => this.animate());
        this.controls.update();
        this.renderer.render(this.scene, this.camera);
    }
}

new FaceToBlendshape3D();
